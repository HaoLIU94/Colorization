{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (bw_conv1_1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu1_1): ReLU()\n",
       "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (relu1_2): ReLU()\n",
       "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2_1): ReLU()\n",
       "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (relu2_2): ReLU()\n",
       "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_1): ReLU()\n",
       "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_2): ReLU()\n",
       "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (relu3_3): ReLU()\n",
       "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_1): ReLU()\n",
       "  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_2): ReLU()\n",
       "  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_3): ReLU()\n",
       "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu5_1): ReLU()\n",
       "  (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu5_2): ReLU()\n",
       "  (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu5_3): ReLU()\n",
       "  (conv6_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu6_1): ReLU()\n",
       "  (conv6_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu6_2): ReLU()\n",
       "  (conv6_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu6_3): ReLU()\n",
       "  (conv7_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu7_1): ReLU()\n",
       "  (conv7_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu7_2): ReLU()\n",
       "  (conv7_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu7_3): ReLU()\n",
       "  (conv8_1): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (relu8_1): ReLU()\n",
       "  (conv8_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu8_2): ReLU()\n",
       "  (conv8_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu8_3): ReLU()\n",
       "  (conv8_313): Conv2d(256, 313, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (activation): Softmax2d()\n",
       "  (class8_ab): Conv2d(313, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn\n",
    "\n",
    "model = torch.nn.Sequential(OrderedDict([\n",
    "    ('bw_conv1_1', torch.nn.Conv2d(1, 64, kernel_size=(3, 3), padding=(1, 1))),\n",
    "    ('relu1_1', torch.nn.ReLU()),\n",
    "    ('conv1_2', torch.nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu1_2', torch.nn.ReLU()),\n",
    "    #\n",
    "#     ('conv1_2norm', torch.nn.BatchNorm2d(64)),\n",
    "    # Batch norm conv1 to add\n",
    "    ('conv2_1', torch.nn.Conv2d(64, 128, kernel_size=(3, 3), padding=(1, 1))),\n",
    "    ('relu2_1', torch.nn.ReLU()),\n",
    "    ('conv2_2', torch.nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu2_2', torch.nn.ReLU()),\n",
    "    #\n",
    "#     ('conv2_2norm', torch.nn.BatchNorm2d(128, affine=False)),\n",
    "    # bacth norm conv2 to add\n",
    "    ('conv3_1', torch.nn.Conv2d(128, 256, kernel_size=(3, 3), padding=(1, 1))),\n",
    "    ('relu3_1', torch.nn.ReLU()),\n",
    "    ('conv3_2', torch.nn.Conv2d(256, 256, kernel_size=(3, 3), padding=(1, 1))),\n",
    "    ('relu3_2', torch.nn.ReLU()),\n",
    "    ('conv3_3', torch.nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu3_3', torch.nn.ReLU()),\n",
    "    # \n",
    "#     ('conv3_3norm', torch.nn.BatchNorm2d(256, affine=False)),\n",
    "    # Batch norm conv3 to add\n",
    "    ('conv4_1', torch.nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1))),\n",
    "    ('relu4_1', torch.nn.ReLU()),\n",
    "    ('conv4_2', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1))),\n",
    "    ('relu4_2', torch.nn.ReLU()),\n",
    "    ('conv4_3', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1))),\n",
    "    ('relu4_3', torch.nn.ReLU()),\n",
    "    #\n",
    "#     ('conv4_3norm', torch.nn.BatchNorm2d(512, affine=False)),\n",
    "    # Batch norm conv4 to add\n",
    "    ('conv5_1', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))),\n",
    "    ('relu5_1', torch.nn.ReLU()),\n",
    "    ('conv5_2', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))),\n",
    "    ('relu5_2', torch.nn.ReLU()),\n",
    "    ('conv5_3', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))),\n",
    "    ('relu5_3', torch.nn.ReLU()),\n",
    "    #\n",
    "#     ('conv5_3norm', torch.nn.BatchNorm2d(512, affine=False)),\n",
    "    # Batch norm conv5 to add\n",
    "    ('conv6_1', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), dilation=(2, 2), padding=(2, 2))),\n",
    "    ('relu6_1', torch.nn.ReLU()),\n",
    "    ('conv6_2', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), dilation=(2, 2), padding=(2, 2))),\n",
    "    ('relu6_2', torch.nn.ReLU()),\n",
    "    ('conv6_3', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), dilation=(2, 2), padding=(2, 2))),\n",
    "    ('relu6_3', torch.nn.ReLU()),\n",
    "    #\n",
    "#     ('conv6_3norm', torch.nn.BatchNorm2d(512, affine=False)),\n",
    "    # Batch norm conv6 to add\n",
    "    ('conv7_1', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), dilation=(1, 1), padding=(1, 1))),\n",
    "    ('relu7_1', torch.nn.ReLU()),\n",
    "    ('conv7_2', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), dilation=(1, 1), padding=(1, 1))),\n",
    "    ('relu7_2', torch.nn.ReLU()),\n",
    "    ('conv7_3', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), dilation=(1, 1), padding=(1, 1))),\n",
    "    ('relu7_3', torch.nn.ReLU()),\n",
    "    #\n",
    "#     ('conv7_3norm', torch.nn.BatchNorm2d(512, affine=False)),\n",
    "    # Batch norm conv7 to add\n",
    "    ('conv8_1', torch.nn.ConvTranspose2d(512, 256, kernel_size=(4,4), stride=(2, 2), padding=(1, 1), dilation=(1, 1))),\n",
    "    ('relu8_1', torch.nn.ReLU()),\n",
    "    ('conv8_2', torch.nn.Conv2d(256, 256, kernel_size=(3, 3), dilation=(1, 1), padding=(1, 1))),\n",
    "    ('relu8_2', torch.nn.ReLU()),\n",
    "    ('conv8_3', torch.nn.Conv2d(256, 256, kernel_size=(3, 3), dilation=(1, 1), padding=(1, 1))),\n",
    "    ('relu8_3', torch.nn.ReLU()),\n",
    "    ('conv8_313', torch.nn.Conv2d(256, 313, kernel_size=(1, 1), dilation=(1, 1), stride=(1, 1))),\n",
    "    # Maybe try using multiplication with constant layer\n",
    "    # Last layer ??\n",
    "    ('activation', torch.nn.Softmax2d()),\n",
    "    ('class8_ab', torch.nn.Conv2d(313, 2, kernel_size=(1, 1), stride=(1, 1), dilation=(1, 1)))\n",
    "]))\n",
    "\n",
    "model.eval()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('models/model.pkl', 'rb') as f:\n",
    "    weights = pickle.load(f,encoding='latin1')\n",
    "W = []\n",
    "B = []\n",
    "for i in range(len(weights)):\n",
    "    if len(weights[i]['weights'])!=0:\n",
    "#         if \"norm\" in weights[i]['name']:\n",
    "#             W.append(weights[i]['weights'][0])\n",
    "#             B.append(weights[i]['weights'][1])\n",
    "#             continue\n",
    "        W.append(weights[i]['weights'][0])#.transpose(2,3,1,0))\n",
    "        B.append(weights[i]['weights'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchnorm = [4,9,16,23,30,37,44]\n",
    "to_load = [0,2,4,5,7,9,10,12,14,16,17,19,21,23,24,26,28,30,31,33,35,37,38,40,42,44,45,47,49,51,53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading weights\n",
    "loaded = 0\n",
    "batchnormed = 0\n",
    "for i in to_load:\n",
    "    if i not in batchnorm:\n",
    "    #     print(\"Weight shape,\", model[i].weight.shape)\n",
    "    #     print(\"loaded shape,\", W[loaded].shape)\n",
    "        model[i - batchnormed].weight = torch.nn.Parameter(torch.from_numpy(W[loaded]), requires_grad=False)\n",
    "        model[i - batchnormed].bias = torch.nn.Parameter(torch.from_numpy(B[loaded]), requires_grad=False)\n",
    "        loaded += 1\n",
    "    else:\n",
    "        loaded += 1\n",
    "        batchnormed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.color as color\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Sequential.forward of Sequential(\n",
       "  (bw_conv1_1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu1_1): ReLU()\n",
       "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (relu1_2): ReLU()\n",
       "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2_1): ReLU()\n",
       "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (relu2_2): ReLU()\n",
       "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_1): ReLU()\n",
       "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_2): ReLU()\n",
       "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (relu3_3): ReLU()\n",
       "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_1): ReLU()\n",
       "  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_2): ReLU()\n",
       "  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_3): ReLU()\n",
       "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu5_1): ReLU()\n",
       "  (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu5_2): ReLU()\n",
       "  (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu5_3): ReLU()\n",
       "  (conv6_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu6_1): ReLU()\n",
       "  (conv6_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu6_2): ReLU()\n",
       "  (conv6_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu6_3): ReLU()\n",
       "  (conv7_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu7_1): ReLU()\n",
       "  (conv7_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu7_2): ReLU()\n",
       "  (conv7_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu7_3): ReLU()\n",
       "  (conv8_1): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (relu8_1): ReLU()\n",
       "  (conv8_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu8_2): ReLU()\n",
       "  (conv8_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu8_3): ReLU()\n",
       "  (conv8_313): Conv2d(256, 313, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (activation): Softmax2d()\n",
       "  (class8_ab): Conv2d(313, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'imgs/ansel_adams3.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5da40d03314b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# load the original image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# img_rgb = caffe.io.load_image('git/colorization/demo/imgs/ansel_adams3.jpg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimg_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imgs/ansel_adams3.jpg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimg_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_grey, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                                (plugin, kind))\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'imgs/ansel_adams3.jpg'"
     ]
    }
   ],
   "source": [
    "# import caffe\n",
    "\n",
    "(H_in,W_in) = 224,224\n",
    "(H_out,W_out) =  56,56\n",
    "\n",
    "# load the original image\n",
    "# img_rgb = caffe.io.load_image('git/colorization/demo/imgs/ansel_adams3.jpg')\n",
    "img_rgb = skimage.io.imread('img/ansel_adams3.jpg') / 255\n",
    "if len(img_rgb.shape) == 2:\n",
    "    img_rgb = np.stack((img_rgb,) * 3, -1)\n",
    "\n",
    "img_lab = color.rgb2lab(img_rgb) # convert image to lab color space\n",
    "img_l = img_lab[:,:,0] # pull out L channel\n",
    "(H_orig,W_orig) = img_rgb.shape[:2] # original image size\n",
    "\n",
    "# create grayscale version of image (just for displaying)\n",
    "img_lab_bw = img_lab.copy()\n",
    "img_lab_bw[:,:,1:] = 0\n",
    "img_rgb_bw = color.lab2rgb(img_lab_bw)\n",
    "\n",
    "# resize image to network input size\n",
    "# img_rs = caffe.io.resize_image(img_rgb,(H_in,W_in)) # resize image to network input size\n",
    "img_rs = resize(img_rgb,(H_in,W_in)) # resize image to network input size\n",
    "img_lab_rs = color.rgb2lab(img_rs)\n",
    "img_l_rs = img_lab_rs[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.Tensor(img_l_rs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = img_l_rs.reshape(1,1, 224,224)\n",
    "test -= 50\n",
    "x = torch.Tensor(test)\n",
    "for i, l in enumerate(model.children()):\n",
    "    print(\"Layer\", l)\n",
    "    x = l(x)\n",
    "#     if i in to_load:\n",
    "#         print(\"Layer weight\", l.weight.numpy().mean(axis=0))\n",
    "#         print(\"Layer bias\", l.bias.mean())\n",
    "#     if i == 4:\n",
    "#         print(l.running_mean)\n",
    "#         print(l.running_var)\n",
    "    print(\"Output shape\", x.shape)\n",
    "    print(\"Output\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = img_l_rs.reshape(1,1, 224,224)\n",
    "test -= 50\n",
    "print(test.mean())\n",
    "res = model.forward(torch.Tensor(test))\n",
    "print(res.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res[0, :, :, :]\n",
    "print(res.shape)\n",
    "res = res.detach().numpy()\n",
    "print(res.shape)\n",
    "res = np.moveaxis(res, 0, -1)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.ndimage.interpolation as sni\n",
    "print(res.mean())\n",
    "ab_dec_us = sni.zoom(res,(1.*H_orig/H_out, 1.*W_orig/W_out, 1)) # upsample to match size of original image L\n",
    "img_lab_out = np.concatenate((img_l[:,:,np.newaxis],ab_dec_us),axis=2) # concatenate with original image L\n",
    "img_rgb_out = (255 * np.clip(color.lab2rgb(img_lab_out),0,1)).astype('uint8') # convert back to rgb\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img_rgb_out)\n",
    "plt.axis('off')\n",
    "\n",
    "# res = res.reshape([H_out,W_out,2])\n",
    "# import scipy.ndimage.interpolation as sni\n",
    "# ab_dec_us = sni.zoom(res,(1.*H_orig/H_out, 1.*W_orig/W_out, 1)) # upsample to match size of original image L\n",
    "# img_lab_out = np.concatenate((img_l[:,:,np.newaxis],ab_dec_us),axis=2) # concatenate with original image L\n",
    "# img_rgb_out = (255*np.clip(color.lab2rgb(img_lab_out),0,1)).astype('uint8') # convert back to rgb\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.imshow(img_rgb_out)\n",
    "# plt.axis('off')\n",
    "\n",
    "path_tores = 'outfile.jpg'\n",
    "scipy.misc.imsave(path_tores, img_rgb_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
