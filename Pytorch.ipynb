{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn\n",
    "\n",
    "model = torch.nn.Sequential(OrderedDict([\n",
    "    ('bw_conv1_1', torch.nn.Conv2d(1, 64, kernel_size=(3, 3), padding=(1, 1))),\n",
    "    ('relu1_1', torch.nn.ReLU()),\n",
    "    ('conv1_2', torch.nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu1_2', torch.nn.ReLU()),\n",
    "    #\n",
    "    ('conv1_2norm', torch.nn.BatchNorm2d(64, affine=False, eps=999.98236)),\n",
    "    # Batch norm conv1 to add\n",
    "    ('conv2_1', torch.nn.Conv2d(64, 128, kernel_size=(3, 3), padding=(1, 1))),\n",
    "    ('relu2_1', torch.nn.ReLU()),\n",
    "    ('conv2_2', torch.nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu2_2', torch.nn.ReLU()),\n",
    "    #\n",
    "    ('conv2_2norm', torch.nn.BatchNorm2d(128, affine=False, eps=999.98236)),\n",
    "    # bacth norm conv2 to add\n",
    "    ('conv3_1', torch.nn.Conv2d(128, 256, kernel_size=(3, 3), padding=(1, 1))),\n",
    "    ('relu3_1', torch.nn.ReLU()),\n",
    "    ('conv3_2', torch.nn.Conv2d(256, 256, kernel_size=(3, 3), padding=(1, 1))),\n",
    "    ('relu3_2', torch.nn.ReLU()),\n",
    "    ('conv3_3', torch.nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu3_3', torch.nn.ReLU()),\n",
    "    # \n",
    "    ('conv3_3norm', torch.nn.BatchNorm2d(256, affine=False, eps=999.98236)),\n",
    "    # Batch norm conv3 to add\n",
    "    ('conv4_1', torch.nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1))),\n",
    "    ('relu4_1', torch.nn.ReLU()),\n",
    "    ('conv4_2', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1))),\n",
    "    ('relu4_2', torch.nn.ReLU()),\n",
    "    ('conv4_3', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1))),\n",
    "    ('relu4_3', torch.nn.ReLU()),\n",
    "    #\n",
    "    ('conv4_3norm', torch.nn.BatchNorm2d(512, affine=False, eps=999.98236)),\n",
    "    # Batch norm conv4 to add\n",
    "    ('conv5_1', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))),\n",
    "    ('relu5_1', torch.nn.ReLU()),\n",
    "    ('conv5_2', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))),\n",
    "    ('relu5_2', torch.nn.ReLU()),\n",
    "    ('conv5_3', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))),\n",
    "    ('relu5_3', torch.nn.ReLU()),\n",
    "    #\n",
    "    ('conv5_3norm', torch.nn.BatchNorm2d(512, affine=False, eps=999.98236)),\n",
    "    # Batch norm conv5 to add\n",
    "    ('conv6_1', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), dilation=(2, 2), padding=(2, 2))),\n",
    "    ('relu6_1', torch.nn.ReLU()),\n",
    "    ('conv6_2', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), dilation=(2, 2), padding=(2, 2))),\n",
    "    ('relu6_2', torch.nn.ReLU()),\n",
    "    ('conv6_3', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), dilation=(2, 2), padding=(2, 2))),\n",
    "    ('relu6_3', torch.nn.ReLU()),\n",
    "    #\n",
    "    ('conv6_3norm', torch.nn.BatchNorm2d(512, affine=False, eps=999.98236)),\n",
    "    # Batch norm conv6 to add\n",
    "    ('conv7_1', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), dilation=(1, 1), padding=(1, 1))),\n",
    "    ('relu7_1', torch.nn.ReLU()),\n",
    "    ('conv7_2', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), dilation=(1, 1), padding=(1, 1))),\n",
    "    ('relu7_2', torch.nn.ReLU()),\n",
    "    ('conv7_3', torch.nn.Conv2d(512, 512, kernel_size=(3, 3), dilation=(1, 1), padding=(1, 1))),\n",
    "    ('relu7_3', torch.nn.ReLU()),\n",
    "    #\n",
    "    ('conv7_3norm', torch.nn.BatchNorm2d(512, affine=False, eps=999.98236)),\n",
    "    # Batch norm conv7 to add\n",
    "    ('conv8_1', torch.nn.ConvTranspose2d(512, 256, kernel_size=(4,4), stride=(2, 2), padding=(1, 1), dilation=(1, 1))),\n",
    "    ('relu8_1', torch.nn.ReLU()),\n",
    "    ('conv8_2', torch.nn.Conv2d(256, 256, kernel_size=(3, 3), dilation=(1, 1), padding=(1, 1))),\n",
    "    ('relu8_2', torch.nn.ReLU()),\n",
    "    ('conv8_3', torch.nn.Conv2d(256, 256, kernel_size=(3, 3), dilation=(1, 1), padding=(1, 1))),\n",
    "    ('relu8_3', torch.nn.ReLU()),\n",
    "    ('conv8_313', torch.nn.Conv2d(256, 313, kernel_size=(1, 1), dilation=(1, 1), stride=(1, 1))),\n",
    "    # Maybe try using multiplication with constant layer\n",
    "    # Last layer ??\n",
    "    ('class8_ab', torch.nn.Conv2d(313, 2, kernel_size=(1, 1), stride=(1, 1), dilation=(1, 1)))\n",
    "]))\n",
    "\n",
    "# model.eval()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot90(W):\n",
    "    for i in range(W.shape[0]):\n",
    "        for j in range(W.shape[1]):\n",
    "            W[i, j] = np.rot90(W[i, j],4)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('models/model.pkl', 'rb') as f:\n",
    "    weights = pickle.load(f,encoding='latin1')\n",
    "W = []\n",
    "B = []\n",
    "for i in range(len(weights)):\n",
    "    if len(weights[i]['weights'])!=0:\n",
    "        if len(weights[i]['weights'][0].shape)>1:\n",
    "            #print(weights[i]['weights'][0].shape)\n",
    "            weights[i]['weights'][0] = rot90(weights[i]['weights'][0])\n",
    "        if \"norm\" in weights[i]['name']:\n",
    "            W.append(weights[i]['weights'][0])\n",
    "            B.append(weights[i]['weights'][1])\n",
    "            continue\n",
    "        W.append(weights[i]['weights'][0])#.transpose(2,3,1,0))\n",
    "        B.append(weights[i]['weights'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_load = [0,2,4,5,7,9,10,12,14,16,17,19,21,23,24,26,28,30,31,33,35,37,38,40,42,44,45,47,49,51,52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading weights\n",
    "loaded = 0\n",
    "for i in to_load:\n",
    "#     print(\"Weight shape,\", model[i].weight.shape)\n",
    "#     print(\"loaded shape,\", W[loaded].shape)\n",
    "    model[i].weight = torch.nn.Parameter(torch.from_numpy(W[loaded]), requires_grad=False)\n",
    "    model[i].bias = torch.nn.Parameter(torch.from_numpy(B[loaded]), requires_grad=False)\n",
    "    loaded += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.color as color\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Sequential.forward of Sequential(\n",
       "  (bw_conv1_1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu1_1): ReLU()\n",
       "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (relu1_2): ReLU()\n",
       "  (conv1_2norm): BatchNorm2d(64, eps=999.98236, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2_1): ReLU()\n",
       "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (relu2_2): ReLU()\n",
       "  (conv2_2norm): BatchNorm2d(128, eps=999.98236, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_1): ReLU()\n",
       "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_2): ReLU()\n",
       "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (relu3_3): ReLU()\n",
       "  (conv3_3norm): BatchNorm2d(256, eps=999.98236, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_1): ReLU()\n",
       "  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_2): ReLU()\n",
       "  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_3): ReLU()\n",
       "  (conv4_3norm): BatchNorm2d(512, eps=999.98236, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu5_1): ReLU()\n",
       "  (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu5_2): ReLU()\n",
       "  (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu5_3): ReLU()\n",
       "  (conv5_3norm): BatchNorm2d(512, eps=999.98236, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv6_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu6_1): ReLU()\n",
       "  (conv6_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu6_2): ReLU()\n",
       "  (conv6_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (relu6_3): ReLU()\n",
       "  (conv6_3norm): BatchNorm2d(512, eps=999.98236, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv7_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu7_1): ReLU()\n",
       "  (conv7_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu7_2): ReLU()\n",
       "  (conv7_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu7_3): ReLU()\n",
       "  (conv7_3norm): BatchNorm2d(512, eps=999.98236, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv8_1): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (relu8_1): ReLU()\n",
       "  (conv8_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu8_2): ReLU()\n",
       "  (conv8_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu8_3): ReLU()\n",
       "  (conv8_313): Conv2d(256, 313, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (class8_ab): Conv2d(313, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hao/anaconda3/envs/py36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "# (H_in,W_in) = model.input_shape[1],model.input_shape[2]# get input shape\n",
    "# (H_out,W_out) = model.output_shape[1],model.output_shape[2]  # get output shape\n",
    "(H_in,W_in) = 224,224\n",
    "(H_out,W_out) =  56,56\n",
    "\n",
    "# load the original image\n",
    "img_rgb = skimage.io.imread('img/lena.bmp')\n",
    "if len(img_rgb.shape) == 2:\n",
    "    img_rgb = np.stack((img_rgb,) * 3, -1)\n",
    "\n",
    "img_lab = color.rgb2lab(img_rgb) # convert image to lab color space\n",
    "img_l = img_lab[:,:,0] # pull out L channel\n",
    "(H_orig,W_orig) = img_rgb.shape[:2] # original image size\n",
    "\n",
    "# create grayscale version of image (just for displaying)\n",
    "img_lab_bw = img_lab.copy()\n",
    "img_lab_bw[:,:,1:] = 0\n",
    "img_rgb_bw = color.lab2rgb(img_lab_bw)\n",
    "\n",
    "# resize image to network input size\n",
    "img_rs = resize(img_rgb,(H_in,W_in)) # resize image to network input size\n",
    "img_lab_rs = color.rgb2lab(img_rs)\n",
    "img_l_rs = img_lab_rs[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(img_l_rs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = img_l_rs.reshape(1,1, 224,224)\n",
    "res = model.forward(torch.Tensor(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 56, 56])\n",
      "(2, 56, 56)\n"
     ]
    }
   ],
   "source": [
    "res = res[0, :, :, :]\n",
    "print(res.shape)\n",
    "res = res.detach().numpy()\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hao/anaconda3/envs/py36/lib/python3.6/site-packages/skimage/color/colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 261893 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/home/hao/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = np.moveaxis(res, 0, -1)\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.ndimage.interpolation as sni\n",
    "ab_dec_us = sni.zoom(res,(1.*H_orig/H_out, 1.*W_orig/W_out, 1)) # upsample to match size of original image L\n",
    "img_lab_out = np.concatenate((img_l[:,:,np.newaxis],ab_dec_us),axis=2) # concatenate with original image L\n",
    "img_rgb_out = (255*np.clip(color.lab2rgb(img_lab_out),0,1)).astype('uint8') # convert back to rgb\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img_rgb_out)\n",
    "plt.axis('off')\n",
    "\n",
    "# res = res.reshape([H_out,W_out,2])\n",
    "# import scipy.ndimage.interpolation as sni\n",
    "# ab_dec_us = sni.zoom(res,(1.*H_orig/H_out, 1.*W_orig/W_out, 1)) # upsample to match size of original image L\n",
    "# img_lab_out = np.concatenate((img_l[:,:,np.newaxis],ab_dec_us),axis=2) # concatenate with original image L\n",
    "# img_rgb_out = (255*np.clip(color.lab2rgb(img_lab_out),0,1)).astype('uint8') # convert back to rgb\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.imshow(img_rgb_out)\n",
    "# plt.axis('off')\n",
    "\n",
    "path_tores = 'outfile.jpg'\n",
    "scipy.misc.imsave(path_tores, img_rgb_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
